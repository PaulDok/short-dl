{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Набор инструментов\n",
    "\n",
    "\n",
    "Тренировка нейросетей может занимать значительное время, так что есть несколько важных вещей, которые надо не забыть:\n",
    "\n",
    "- сохранять промежуточные/лучшие веса (делать чекпоинты)\n",
    "- писать логи в адекватном формате (так, чтобы они не терялись при перезапуске тетрадки)\n",
    "\n",
    "\n",
    "**План тетрадки**\n",
    "1. Логгирование и tensorboard\n",
    "2. Сохранение-восстановление весов\n",
    "3. Dataset API в pytorch\n",
    "4. Выбор LR\n",
    "5. Практика\n",
    "6. Затухающие градиенты и Residual-блоки\n",
    "\n",
    "\n",
    "Есть множество вариантов хранения логов и артефактов (весов) обучения. Прежде чем выбрать какое-то коробочное решение имеет смысл попробовать собрать несколько своих велосипедов.\n",
    "\n",
    "\n",
    "## Логгирование\n",
    "\n",
    "В предыдущих тетрадках мы хранили тренировочные логи в словарях со списками. Это неплохой вариант, его можно сериализовать в файлы и рисовать в отдельном коде. Однако эти логи бесполезны без знания _схемы_.\n",
    "\n",
    "Довольно распространенным вариантом является формат tensorboard: это бинарный формат (не текстовые, как json) с готовым просмотрщиком.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[Tensorboard](https://www.tensorflow.org/tensorboard) -- это pip-installable web-приложение.\n",
    "\n",
    "```\n",
    "tensorboard --logdirs=./some-folder/with/events-files\n",
    "# зайти на http://localhost:6006\n",
    "```\n",
    "<img src=\"./img/tb.png\"/>\n",
    "\n",
    "При желании, можно написать python-код для парсинга логов и делать что-то с ними руками.\n",
    "\n",
    "Чтобы писать логи в pytorch есть класс `torch.utils.tensorboard.SummaryWriter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "writer = SummaryWriter(\"./check-this/\")\n",
    "\n",
    "fake_loss = 1 / np.arange(1, 100)\n",
    "for global_step, point in enumerate(fake_loss):\n",
    "    writer.add_scalar(\"lossy\", point, global_step=global_step)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls check-this\n",
    "\n",
    "# поставьте tensorboard\n",
    "# запустите его в папке с логами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TB умеет рисовать множество графиков, для этого достаточно писать их в разные папки, лежащие в `--logdir`.\n",
    "\n",
    "Хорошая практика: для каждого запуска обучения заводить отдельную папку с логами, записывать туда словарь с гиперпараметрами и логи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Состояния модели и оптимизатора\n",
    "\n",
    "Нам часто бывает необходимо сохранить/загрузить веса модели. Расхожее название для этого `checkpoint`.\n",
    "В DL термином `checkpointing` называют так же метод бекпропа, позволяющий экономить память ценой дополнительных вычислений (https://pytorch.org/docs/stable/checkpoint.html#torch-utils-checkpoint).\n",
    "\n",
    "У торчевых моделей и оптимизаторов есть методы для получения и загрузки состояний:\n",
    "- `.state_dict()` возвращает словарь (или почти словарь) с весами\n",
    "- `.load_state_dict()` загружает веса из словаря в модельку\n",
    "\n",
    "\n",
    "\n",
    "Для сохранения/загрузки словарей с тензорами в файлы есть простые функции `torch.save(some_dict, path)`, `torch.load(path)`. Сравните с использованием `pickle` или `json`!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "some_model = nn.Sequential(nn.Linear(10, 10))\n",
    "print(some_model.state_dict())\n",
    "\n",
    "opt = optim.Adam(some_model.parameters())\n",
    "print(opt.state_dict())\n",
    "\n",
    "\n",
    "torch.save({\"model_stuff\": some_model.state_dict(), \"opt_stuff\": opt.state_dict()}, \"./that.is.it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(\"./that.is.it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset API\n",
    "\n",
    "Подготовка данных легко может стать бутылочным горлышком, когда на подготовку очередного батча уходит больше времени, чем на forward+backward проходы по сети.\n",
    "Проблема усложняется особенностями python: чтобы использовать несколько ядер CPU для подготовки данных надо постараться.\n",
    "\n",
    "В Pytorch работа с данными строится на двух классах из [troch.utils.data](https://pytorch.org/docs/stable/data.html): `Dataset` и `DataLoader`:\n",
    "\n",
    "- `Dataset` отвечает за подготовку одного примера\n",
    "- `DataLoader` отвечает за выбор примеров, склейку их в один батч и распараллеливание на CPU, поддерживает итерирование.\n",
    "\n",
    "\n",
    "Для решения задачи обычно пишут кастомные Dataset-классы, для этого нужно написать всего две функции:\n",
    "- `.__len__(self)` возвращает количество примеров в датасете;\n",
    "- `.__getitem__(self, item)` возвращает item-ный по счету пример из датасета.\n",
    "\n",
    "Задачи DataLoader достаточно сложно аккуратно реализовать и лучше использовать готовый. Он довольно гибкий, все основные моменты кастомизируются заданием функций:\n",
    "```\n",
    "torch.utils.data.DataLoader(\n",
    "    dataset,            # собственно экземпляр класса Dataset, из которого надо доставать примеры\n",
    "    batch_size=1,       # количество примеров в батче\n",
    "    drop_last=False,    # нужно ли при итерировании выбрасывать неполные батчи? (такое бывает, если число примеров не делится нацело на batch_size\n",
    "    shuffle=False,      # перемешивать ли примеры\n",
    "    sampler=None,       # чтобы перемешивать примеры кастомно\n",
    "    batch_sampler=None, # чтобы использовать кастомный отбор примеров в батч\n",
    "    num_workers=0,      # на сколько процессов запараллелить подготовку данных\n",
    "    collate_fn=None,    # функция, которая будет склеивать примеры в батчи\n",
    "    # остальные аргументы более технические, сейчас можно не рассматривать\n",
    "    pin_memory=False,   \n",
    "    timeout=0, \n",
    "    worker_init_fn=None, \n",
    "    multiprocessing_context=None, \n",
    "    generator=None)\n",
    "```\n",
    "\n",
    "Напишите два датасета для работы с FashionMnist: один готовит данные как вектора, другой как картинки\n",
    "\n",
    "\n",
    "**NB: FashionMNIST возвращает картинки в формате PIL.Image.Image, чтобы сделать из него понятный np.array, просто вызовите np.array(PIL_IMAGE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "\n",
    "class VectorSet:\n",
    "    def __init__(self, train=True):\n",
    "        self.data = FashionMNIST(\"./tmp\", train=train, download=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        <your code>\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        # сделайте вектор с float32 числами\n",
    "        <your code>\n",
    "        return dict(\n",
    "            sample=...,\n",
    "            label=...,\n",
    "        )\n",
    "\n",
    "vs = VectorSet()\n",
    "print(vs[0])\n",
    "        \n",
    "class ImageSet:\n",
    "    def __init__(self, train=True):\n",
    "        self.data = FashionMNIST(\"./tmp\", train=train, download=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        <your code>\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        # сделайте одноканальную картинку [1, 28, 28] с float32\n",
    "        <your code>\n",
    "        return dict(\n",
    "            sample=...,\n",
    "            label=...,\n",
    "        )\n",
    "    \n",
    "ms = ImageSet()\n",
    "print(ms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверьте итерирование, именно его мы используем в train-loop'е\n",
    "vl = DataLoader(vs, batch_size=4)\n",
    "for batch in vl:\n",
    "    for k, v in batch.items():\n",
    "        print(k, v.shape)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Замечания по Dataset/Dataloader\n",
    "\n",
    "1. Dataset может возвращать что угодно (туплы или словари) с отдельными числами или массивами (numpy или уже готовыми torch.tensor). Удобно возвращать словари с читабельными ключами. Тогда \n",
    "\n",
    "2. Имеет смысл поглядеть в [стандартный collate_fn](https://github.com/pytorch/pytorch/blob/master/torch/utils/data/_utils/collate.py#L42): он умеет клеить в батчи и конвертировать в тензора самые разнообразные данные. Однако, массивы разной длины не сможет. Так что для \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор оптимального LR\n",
    "\n",
    "\n",
    "Для выбора оптимального LR удобно использовать т.н. Learning Rate Range Test, часто процедуру называют просто find_lr. Под капотом проход по тренировочной эпохе с lr, изменяемым на каждом батче по формуле:\n",
    "\n",
    "$$\n",
    "\\mathrm{it} = \\frac{\\mathrm{step}}{\\mathrm{total steps}}\\\\\n",
    "\\mathrm{lr} = \\exp\\left\\{ \n",
    "    (1 - t ) \\log a + t \\log b\n",
    "\\right\\}\n",
    "$$\n",
    "\n",
    "Чтобы поменять LR для всех оптимизируемых параметров, можно пройтись по ним циклом:\n",
    "\n",
    "```\n",
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] = lr\n",
    "```\n",
    "\n",
    "\n",
    "<img src=\"https://www.jeremyjordan.me/content/images/2018/02/lr_finder.png\"/>\n",
    "\n",
    "_картинка из бложика [Jeremy Jordan](https://www.jeremyjordan.me/nn-learning-rate/)_\n",
    "\n",
    "\n",
    "Идея приема простая: пока LR меньше некоторого порога на каждом шаге градиентного спуска веса просто не меняются (в частности из-за особенностей операций с плавающей точкой).\n",
    "При очень большом LR мы шагаем слишком далеко и уходим от точки экстремума. \n",
    "\n",
    "Оптимальный LR лежит где-то между ними. Экспоненциальная формула изменения LR позволяет с должным качеством найти хорошую точку.\n",
    "\n",
    "\n",
    "\n",
    "Если интересно: [статья , в которой эту технику предложили и активно использовали](https://arxiv.org/pdf/1506.01186.pdf).\n",
    "\n",
    "\n",
    "**Some math notes**\n",
    "\n",
    "У типов данных с плавающей точкой есть арифметические особенности:\n",
    "\n",
    "$$\n",
    "x + \\delta == x,\\,\\mathrm{если}\\; \\delta < 5.96 \\cdot 10^{-8} x\n",
    "$$\n",
    "\n",
    "К слову, это еще одна причина присматривать за величинами активаций, нормировать данные и таргет в случае регрессии. Можно было бы перейти на float64, но (вычислительно) дешевле быть аккуратными на float32.\n",
    "\n",
    "Благодаря NVIDIA на новом железе получается эффективно пользоваться форматом fp16, но это требует некоторых трюков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# просто попробуйте\n",
    "w = np.float32(1.0)\n",
    "too_much = np.float32(5.97e-8)\n",
    "too_not = np.float32(5.96e-8)\n",
    "print(w == w + too_much)\n",
    "print(w == w + too_not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice!\n",
    "\n",
    "\n",
    "1. Пишем сеть (полносвязную), лосс\n",
    "2. Задаем Dataset, и думаем про transform\n",
    "3. Пишем train-loop & find-lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "# сделайте DataLoader выдающий вектора из FashionMNIST\n",
    "\n",
    "train_loader = ...\n",
    "val_loader = ...\n",
    "\n",
    "\n",
    "# проверочный батч, пригодится дальше\n",
    "for some_batch in train_loader:\n",
    "    print(some_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделайте простую сеть для классификации FashionMNIST с тремя полносвязными слоями с нелинейностями между ними.\n",
    "Все промежуточные тензора пусть имеют 40 каналов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VeryModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "    \n",
    "    def compute_all(self, batch):  # удобно сделать функцию, в которой вычисляется лосс по пришедшему батчу\n",
    "        loss = ...\n",
    "        metrics = dict()\n",
    "        return loss, metrics\n",
    "\n",
    "# проверяйте работоспособность сразу\n",
    "net = VeryModel()\n",
    "net.compute_all(some_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите find_lr (для подбора хорошего LR) и train_model (для тренировки и валидации).\n",
    "\n",
    "Тренировочные кривые можно рисовать здесь или сохранять с помощью SummaryWriter для tensorboard.\n",
    "(результаты find_lr лучше рисовать здесь, будет проще подобрать масштаб)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lr(model, opt, trainloader):\n",
    "    pass\n",
    "\n",
    "def train_model(model, opt, trainloader, valloader, epochs=10):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подберите LR\n",
    "net = VeryModel()\n",
    "opt = optim.SGD(net.parameters(), lr=1e-3)\n",
    "find_lr(net, opt, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VeryModel()\n",
    "opt = optim.SGD(net.parameters(), lr=<...>)\n",
    "train_model(net, opt, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Эксперимент с затухающими градиентами\n",
    "\n",
    "Сделайте функцию, собирающую нормы градиентов по слоям.\n",
    "Функция должна работать с GPU и CPU-моделями!\n",
    "\n",
    "Ключи в словаре с нормами сделайте по именам слоев (используйте `model.named_parameters()` из предыдущей тетрадки)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grad_norms(model):\n",
    "    <your code>\n",
    "    return {\"some.weight\": some float}\n",
    "\n",
    "# код для проверки корректности\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(7, 11),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(11, 10),\n",
    ")\n",
    "\n",
    "x = torch.ones(13, 7)\n",
    "loss = model(x).mean()\n",
    "loss.backward()\n",
    "\n",
    "assert get_grad_norms(model).keys() == {\"0.weight\", \"0.bias\", \"2.weight\", \"2.bias\"}\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    model.to(device)\n",
    "    x = x.to(device)\n",
    "    loss = model(x).mean()\n",
    "    loss.backward()\n",
    "    assert get_grad_norms(model).keys() == {\"0.weight\", \"0.bias\", \"2.weight\", \"2.bias\"}\n",
    "    print(\"All is fine\")\n",
    "else:\n",
    "    print(\"GPU unchecked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Глубокая сеть\n",
    "\n",
    "Сделайте глубокую сеть из полносвязных слоев и нелинейностей.\n",
    "8 FC-слоев с нелинейностями между ними, постройте нормы градиентов по слоям от номера шага.\n",
    "Размеры промежуточных тензоров возьмите 20 или 40 каналов.\n",
    "\n",
    "Добавьте в функцию `train_model` вывод норм градиентов.\n",
    "\n",
    "Ожидаемая картинка выглядит примерно так: <img src=\"./img/sad_network.png/\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VeryModel()\n",
    "opt = optim.SGD(net.parameters(), lr=<...>)\n",
    "train_model(net, opt, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть по крайней мере несколько способов, которые могут помочь заставить эту сеть учиться (без изменения глубины):\n",
    "- использовать другую функцию активации\n",
    "- выбрать LR для каждого слоя\n",
    "- собрать сеть из других блоков\n",
    "\n",
    "Вы можете попробовать первый или второй (или какой-нибудь свой) вариант, но сопроводите, пожалуйста, код письменными рассуждениями.\n",
    "\n",
    "### Residual Blocks\n",
    "\n",
    "Если сеть собирать из блоков вида\n",
    "```\n",
    "y = x + F(x)\n",
    "```\n",
    "где F(x) -- это FC-слой + нелинейность, градиенты будут протекать гораздо лучше (поскольку есть путь без нелинейностей).\n",
    "\n",
    "<img src=\"./img/resblock.png\">\n",
    "\n",
    "Реализуйте каким-либо образом ResNet с 8 нелинейностями с тем же количеством каналов.\n",
    "\n",
    "Постройте картинку с градиентами по слоям для каждого шага."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResModel()\n",
    "opt = optim.SGD(net.parameters(), lr=<...>)\n",
    "train_model(net, opt, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
