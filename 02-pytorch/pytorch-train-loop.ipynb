{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3x3zSYPaY9vU"
   },
   "source": [
    "# Pytorch Introduction\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/m12sl/short-dl/blob/master/02-pytorch/pytorch-train-loop.ipynb)\n",
    "\n",
    "В этой тетрадке мы напишем познакомимся с базовыми возможностями pytorch.\n",
    "\n",
    "**Цели тетрадки**\n",
    "\n",
    "1. Познакомиться с типами данных и арифметикой в pytorch.\n",
    "1. Научиться пользоваться автоматическим дифференцированием.\n",
    "1. Попробовать low-level и high-level API на нескольких задачах.\n",
    "\n",
    "\n",
    "\n",
    "**План работы**\n",
    "\n",
    "1. Познакомиться на примерах с pytorch API.\n",
    "1. Научиться получать градиенты для переменных.\n",
    "1. Реализовать линейную регрессию на pytorch.\n",
    "1. Натренировать классификатор FashionMNIST с помощью high-level API.\n",
    "1. Зафайнтюнить предобученную модель из пакета torchvision.\n",
    "\n",
    "\n",
    "## Материалы по pytorch:\n",
    "\n",
    "+ https://pytorch.org/resources/\n",
    "+ https://pytorch.org/docs/stable/index.html\n",
    "+ ходить по исходникам с помощью IDE\n",
    "+ [Классная статья про pytorch internal](http://blog.ezyang.com/2019/05/pytorch-internals/)\n",
    "\n",
    "\n",
    "## Важные модули:\n",
    "\n",
    "- `autograd` -- функции для вычисления производных\n",
    "- `nn`-- классы для слоев и моделей\n",
    "- `nn.functional` -- функциональный API для некоторых операций\n",
    "- `nn.init` -- различные варианты инциализации\n",
    "- `optim` -- оптимизаторы\n",
    "- `utils.data` -- API для работы с данными (Dataset & DataLoader)\n",
    "\n",
    "\n",
    "**Дополнительные пакеты:**\n",
    "- `torchvision` -- предобученные модели, преобразования картинок и датасеты\n",
    "- `torchaudio` -- датасеты и полезные преобразования для работы со звуком\n",
    "- `torchtext` -- датасеты и полезные функции для работы с текстом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# install requirements\n",
    "! pip install torchviz torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uSIb8PLGY9vZ"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import clear_output  # потребуется для перерисовки графиков\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchviz  # потребуется для отображения графов\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основа вычислений: torch.Tensor\n",
    "\n",
    "\n",
    "Это практически `numpy.ndarray` с некоторыми дополнительными возможностями.\n",
    "\n",
    "Официальная документация: https://pytorch.org/docs/stable/tensors.html\n",
    "\n",
    "\n",
    "**Важные поля:**\n",
    "- `.device` -- `cuda` или `cpu`\n",
    "- `.dtype` -- тип переменной, в отличие от numpy, преобразования типов приходится делать явно\n",
    "- `.requires_grad` -- флаг говорит, должен ли автоград вычислять градиенты для этой переменной\n",
    "- `.data` -- содержимое переменной\n",
    "- `.grad` -- градиенты, сохраненные для этой переменной\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 482,
     "status": "ok",
     "timestamp": 1547404548924,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "pe29HnAKY9vd",
    "outputId": "fcca8236-f309-421d-e87c-d6fbf063f8d5"
   },
   "outputs": [],
   "source": [
    "# numpy world\n",
    "x = np.arange(16).astype(np.float32).reshape(4, 4)\n",
    "\n",
    "print(\"X :\\n %s\" % x)\n",
    "print(\"add 5 :\\n%s\" % (x + 5))\n",
    "print(\"X*X^T  :\\n\", np.dot(x, x.T))\n",
    "print(\"mean over cols :\\n%s\" % (x.mean(axis=-1)))\n",
    "print(\"cumsum of cols :\\n%s\" % (np.cumsum(x, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 673,
     "status": "ok",
     "timestamp": 1547404555089,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "mFmEwrWQY9wl",
    "outputId": "0fbde5e5-8fed-4515-a7f3-b4f87a29a31d"
   },
   "outputs": [],
   "source": [
    "# pytorch world\n",
    "x = torch.arange(16).float().view(4, 4)\n",
    "\n",
    "print(\"X :\\n%s\" % x)\n",
    "print(\"add 5 :\\n%s\" % (x + 5))\n",
    "print(\"X*X^T  :\\n\", torch.matmul(x, x.transpose(1, 0)))\n",
    "print(\"mean over cols :\\n\", torch.mean(x, dim=-1))\n",
    "print(\"cumsum of cols :\\n\", torch.cumsum(x, dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XzYCigYxY9wt"
   },
   "source": [
    "Numpy и Pytorch не требуют описания статического графа вычислений.\n",
    "Результат получается сразу при выполнении.\n",
    "\n",
    "**Можно отлаживаться с помощью pdb/ipdb или просто print.**\n",
    "\n",
    "API несколько различается:\n",
    "\n",
    "|        numpy        |      pytorch    |\n",
    "|:-------             |         -------:|\n",
    "| `x.reshape([1,2,8])`| `x.view(1,2,8)` |\n",
    "| `x.sum(axis=-1)`    | `x.sum(dim=-1)` |\n",
    "| `x.astype('int64')` | `x.type(torch.int64)` |\n",
    "\n",
    "\n",
    "Легко конвертировать между собой:\n",
    "\n",
    "```python\n",
    "tt = torch.from_numpy(npx) # -- вернет Tensor\n",
    "npx = tt.numpy() # -- вернет Numpy Array\n",
    "```\n",
    "\n",
    "Преобразовать тензор из одного числа в обычное питоновское число:\n",
    "```python\n",
    "torch.tensor([1]).item() # 1\n",
    "```\n",
    "\n",
    "**NB: тензор тащит за собой весь вычислительный граф, чтобы можно было сделать backward, так при откладывании чисел (например для логов) обязательно доставайте сами числа, не складывайте тензора в массивы между итерациями -- это приведет к утечке памяти**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вычислительный граф\n",
    "\n",
    "Вычислительный граф строится по выражениям, в которых участвует `torch.tensor`.\n",
    "\n",
    "Все вершины в графе можно разбить на два класса: Leaf (листовые) и Non-Leaf (не листовые) вершины. \n",
    "\n",
    "Если тензор не зависит от других, он является листовой вершиной.\n",
    "\n",
    "Для оптимизации памяти pytorch будет считать градиенты только для _листовых_ переменных с выставленным флагом `requires_grad=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1., 2., 3., 4.], requires_grad=True)  # leaf tensor\n",
    "alpha = torch.tensor([-1.0, ]) # leaf, but without grads\n",
    "y = x + 1  # not a leaf variable\n",
    "z = x * y * alpha\n",
    "print(z)\n",
    "\n",
    "\n",
    "torchviz.make_dot(z, {\"input x\": x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1., 2., 3., 4.], requires_grad=True)  # leaf tensor\n",
    "alpha = torch.tensor([-1.0, ]) # leaf, but without grads\n",
    "y = x + 1  # not a leaf variable\n",
    "loss = (alpha * y).mean()\n",
    "\n",
    "print(\"BEFORE BACKWARD\")\n",
    "[print(f\"var: {var}\\ngrad: {var.grad}\\n\") for var in [x, y, alpha]]\n",
    "\n",
    "loss.backward()\n",
    "print(\"\\nAFTER BACKWARD:\")\n",
    "[print(f\"var: {var}\\ngrad: {var.grad}\\n\") for var in [x, y, alpha]]\n",
    "\n",
    "    \n",
    "# просто так повторно запросить .backward() нельзя, попробуйте раскомментить:\n",
    "# loss.backward()\n",
    "\n",
    "# но можно сделать еще один тензор (зависящий от предыдущих переменных) и запросить .backward() в нем:\n",
    "# loss2 = (alpha * y).mean()\n",
    "# loss2.backward()\n",
    "\n",
    "# print(\"\\nAFTER BACKWARD2:\")\n",
    "# [print(f\"var: {var}\\ngrad: {var.grad}\\n\") for var in [x, y, alpha]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, как пользоваться автоматическим дифференцированием:\n",
    "\n",
    "1. Создать переменную: `a = torch.tensor(..., requires_grad=True)`\n",
    "\n",
    "2. Определить какую-нибудь дифференцируемую функцию `loss = whatever(a)`\n",
    "\n",
    "3. Запустить backward-проход `loss.backward()`\n",
    "\n",
    "4. Градиенты будут доступны в `a.grad`\n",
    "\n",
    "5. При повторных вызовах `.backward()` (у разных лоссов) градиенты в задействованных переменных суммируются. Это позволяет использовать несколько функций ошибок или виртуально увеличивать `batch_size`. Поэтому, перед каждый вычислением градиентов, стоит обнулять старые градиенты.\n",
    "\n",
    "**NB: вычисление градиентов работает только для тензоров с вещественным типом данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 491,
     "status": "error",
     "timestamp": 1547405637406,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "r3rKaDeHkCDx",
    "outputId": "4a826849-c57c-49e2-c2fc-56a81fcc676b"
   },
   "outputs": [],
   "source": [
    "# will not work\n",
    "x = torch.tensor([1, 2, 3, 4], requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MB2E0HXc0YQ5"
   },
   "source": [
    "Чтобы выключить автоматическое вычисление градиентов, есть три возможности:\n",
    "- выставить `requires_grad=False`\n",
    "- использовать контекст-менеджер `with torch.no_grad()`\n",
    "- применить `detach`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 480,
     "status": "ok",
     "timestamp": 1547410105269,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "0whd_wGr0Xlg",
    "outputId": "bc502448-c324-4f72-83dd-89f8966af73f"
   },
   "outputs": [],
   "source": [
    "t = torch.tensor([1.0, 0.5])\n",
    "x = torch.tensor([1.], requires_grad=True)\n",
    "y = x**2\n",
    "print(t.requires_grad)\n",
    "print(x.requires_grad)\n",
    "print(y.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.exp(x)\n",
    "    print(z.requires_grad)\n",
    "    \n",
    "# detach from the graph\n",
    "w = torch.log(x).detach()\n",
    "print(w.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ocw1MsBIkLYh"
   },
   "source": [
    "# Линейная регрессия\n",
    "\n",
    "Рассмотрим пример линейной регрессии на датасете Boston. \n",
    "\n",
    "Для простоты оставим одну компонету признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 715,
     "status": "ok",
     "timestamp": 1547406896812,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "X34atyS5Y9xA",
    "outputId": "8e34a964-ce17-4a8d-fc77-04389e80dee2"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "X, Y = load_boston(return_X_y=True)\n",
    "print(X.shape)\n",
    "X = X[:, -1] / X[:, -1].std()\n",
    "Y = Y / Y.std()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X, Y)\n",
    "plt.ylabel(\"target\")\n",
    "plt.xlabel(\"feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно провести прямую линию, минимизирующую MSE.\n",
    "Запишем вычислительный граф и получим градиенты для одного шага градиентного спуска:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 529,
     "status": "ok",
     "timestamp": 1547406897141,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "QGfIe-HzY9xJ",
    "outputId": "a1742d23-2223-4bc4-c7dd-3eba8dabf135"
   },
   "outputs": [],
   "source": [
    "# model tensors\n",
    "w = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# data tensors\n",
    "x = torch.from_numpy(X).type(torch.float)\n",
    "y = torch.from_numpy(Y).type(torch.float)\n",
    "\n",
    "y_pred = w * x + b\n",
    "loss = torch.mean((y_pred - y)**2)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "#now w.grad is a tensor containing gradient of L w.r.t. w\n",
    "print(\"dL/dw = \\n\", w.grad)\n",
    "print(\"dL/db = \\n\", b.grad)\n",
    "\n",
    "\n",
    "torchviz.make_dot(loss, {\"Weight: W\": w, \"Weight: b\": b})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lEn3f-9QY9xc"
   },
   "source": [
    "Предлагается реализовать обучение модели линейной регрессии.\n",
    "\n",
    "**Напишите код для обновления весов:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1547407342686,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "g3wj6u71Y9xe",
    "outputId": "e216320b-001a-4438-d9cb-c855928e214a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = torch.from_numpy(X).type(torch.float)\n",
    "y = torch.from_numpy(Y).type(torch.float)\n",
    "\n",
    "for i in range(100):    \n",
    "    # напишите шаг градиентного спуска\n",
    "    <your code>\n",
    "    \n",
    "    # zero gradients\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    \n",
    "    # the rest of code is just bells and whistles\n",
    "    if (i + 1) % 5==0:\n",
    "        #draw linear regression prediction vs data\n",
    "        clear_output(True)\n",
    "        plt.axhline(0, color='gray')\n",
    "        plt.axvline(0, color='gray')\n",
    "        plt.scatter(x.numpy(),y.numpy())\n",
    "        plt.plot(x.numpy(),y_pred.data.numpy(),color='orange')\n",
    "        plt.show()\n",
    "\n",
    "        print(\"loss = \", loss.item())\n",
    "        if loss.item() < 0.5:\n",
    "            print(\"Done!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYR7GonVY9xm"
   },
   "source": [
    "# Optimizers\n",
    "\n",
    "В этом примере мы пользовались простым правилом для градиентного спуска:\n",
    "  \n",
    "$$\\theta^{n+1} = \\theta^{n} - \\alpha \\nabla_{\\theta}L$$\n",
    "\n",
    "\n",
    "Единственным параметром в нем является $\\alpha$ -- это `learning_rate`.\n",
    "\n",
    "На практике часто используют различные модификации (например _Momentum_):\n",
    "\n",
    "$$\\theta^{n+1} = \\theta^{n} - U^{n}\\\\\n",
    "U^{n} = \\gamma U^{n-1} + \\alpha \\nabla_{\\theta}(L)\n",
    "$$\n",
    "\n",
    "Хороший обзор алгоритмов оптимизации для сетей можно посмотреть [тут](http://ruder.io/optimizing-gradient-descent/).\n",
    "\n",
    "\n",
    "\n",
    "Pytorch предоставляет практически все широкораспространненные оптимизаторы:    \n",
    "http://pytorch.org/docs/master/optim.html\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Оптимизаторы очень просто использовать:\n",
    "\n",
    "- при создании оптимизатора требуется указать список переменных, с которыми он будет работать\n",
    "- `opt.zero_grad()` сбрасывает градиенты\n",
    "- `opt.step()` применяет `update` ($U^{n}$) к весам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1547407528989,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "m_Sdf5aQY9xn",
    "outputId": "5d17921d-add1-48ff-b8a7-7b2f5ba63780"
   },
   "outputs": [],
   "source": [
    "# get data\n",
    "x = torch.from_numpy(X).type(torch.float)\n",
    "y = torch.from_numpy(Y).type(torch.float)\n",
    "# model tensors\n",
    "w = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# define optimizer\n",
    "opt = torch.optim.RMSprop([w, b], lr=0.1)\n",
    "\n",
    "for i in range(100):\n",
    "    # compute loss\n",
    "    y_pred = w * x  + b\n",
    "    loss = torch.mean((y_pred - y) ** 2)\n",
    "    \n",
    "    # backprop and gradient descent\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    \n",
    "    #the rest of code is just bells and whistles\n",
    "    if (i + 1) % 5 == 0:\n",
    "        #draw linear regression prediction vs data\n",
    "        clear_output(True)\n",
    "        plt.axhline(0, color='gray')\n",
    "        plt.axvline(0, color='gray')\n",
    "        plt.scatter(x.numpy(), y.numpy())\n",
    "        plt.plot(x.numpy(), y_pred.data.numpy(), color='orange')\n",
    "        plt.show()\n",
    "\n",
    "        print(\"loss = \", loss.item())\n",
    "        if loss.item() < 0.5:\n",
    "            print(\"Done!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "KeVrAA6LY9xu"
   },
   "source": [
    "## Highlevel-API \n",
    "\n",
    "При работе с нейронными сетями становится неудобно контролировать переменные с весами по-отдельности. \n",
    "Pytorch предоставляет высокоуровневый API для моделей: [nn.Module](http://pytorch.org/docs/master/nn.html#torch.nn.Module)\n",
    "\n",
    "Чтобы воспользоваться моделью необходимо отнаследоваться от `torch.nn.Module`, определить слои и описать `forward`. \n",
    "\n",
    "`backward` будет вычислен автоматически."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher-level API:\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_channels=784, hidden_size=40):\n",
    "        super(Net, self).__init__()\n",
    "        # here you construct weights for layers\n",
    "        self.fc1 = nn.Linear(784, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, 10)\n",
    "        # важно чтобы слои записывались как методы класса\n",
    "        # self.some_layers = [nn.Linear(), nn.Linear(), ...] сломает разные полезные из-коробочные функции\n",
    "        # Если очень нужно, есть специальный класс nn.ModuleList\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # here you describe usage of layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "    # backward function computes automaticaly\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net(torch.rand(3, 784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простую цепочку слоев удобно заворачивать в `nn.Sequential`.\n",
    "В таком случае не придется писать `.forward`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(784, 40),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40, 40),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40, 10),\n",
    "    nn.LogSoftmax(dim=1),\n",
    ")\n",
    "net(torch.rand(32, 784)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве датасета возьмем FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3821,
     "status": "ok",
     "timestamp": 1547407542987,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "MAJhDSN8Y9xv",
    "outputId": "cfab66d1-1193-4835-f0bd-a591357e385b"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "default_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Lambda(lambda t: t.reshape(-1))]  # let's convert image (28, 28) to vector (784)\n",
    ")\n",
    "train_dataset = FashionMNIST(\"./tmp\", train=True, download=True, transform=default_transform)\n",
    "val_dataset = FashionMNIST(\"./tmp\", train=False, download=True, transform=default_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, shuffle=True, batch_size=32)\n",
    "\n",
    "train_dataset[0][0].shape\n",
    "plt.figure(figsize=[6, 6])\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.title(\"Label: %i\" % train_dataset[i][1])\n",
    "    plt.imshow(train_dataset[i][0].reshape(28, 28), cmap='gray')  # don't forget convert vector to image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7y6TCrdxY9xz"
   },
   "source": [
    "**Напишите код для тренировки по аналогии с обучением линейной регрессии и прошлой тетрадки**\n",
    "\n",
    "Предлагается для треккинга экспериментов использовать [`defaultdict`](https://docs.python.org/3.3/library/collections.html#defaultdict-objects)\n",
    "\n",
    "**NB: обязательно доставайте числа из тензоров, не сохраняйте тензора с каждой итерации в какой-нибудь буффер.\n",
    "Каждый тензор тащит за собой информацию для построения графа, это ест память**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 826
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 722,
     "status": "ok",
     "timestamp": 1547407669131,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "cAH1muhlY9x2",
    "outputId": "a517cc92-0163-4f98-d2a8-a5f1cc9d0425"
   },
   "outputs": [],
   "source": [
    "def train_model(model, opt, trainloader, valloader, epochs=1):\n",
    "    step = 0\n",
    "    logs = defaultdict(list)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch in tqdm(trainloader):\n",
    "            # тренировочные шаги\n",
    "            <your code>\n",
    "            # добавьте точность и ошибку в логи\n",
    "            logs['acc'].append(<...>)\n",
    "            logs['loss'].append(<...>)\n",
    "            step += 1\n",
    "            \n",
    "        model.eval()\n",
    "        tmp = defaultdict(list)  # аккумулятор для накопления и усреднения результатов за валидацию\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(valloader):\n",
    "                # валидационные шаги\n",
    "                <your code>\n",
    "                # добавьте точность и ошибку в логи\n",
    "                tmp['acc'].append(<...>)\n",
    "                tmp['loss'].append(<...>)\n",
    "        for key, values in tmp.items():\n",
    "            logs[f\"val_{key}\"].append(np.mean(values))\n",
    "            logs[\"step\"].append(step)\n",
    "        \n",
    "    \n",
    "        plt.figure()\n",
    "        plt.plot(logs['loss'], label='train loss', zorder=1)\n",
    "        plt.scatter(logs[\"step\"], logs['val_loss'], marker='+', s=180, label='val loss', zorder=10)\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    return model\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 40),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40, 40),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40, 10),\n",
    "    nn.LogSoftmax(dim=1),\n",
    ")\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "    \n",
    "\n",
    "train_model(model, opt, train_loader, val_loader, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-cKfcm8rY9yU"
   },
   "source": [
    "## Fine Tuning\n",
    "\n",
    "\n",
    "Для многих прикладных задач не существует больших датасетов с хорошей разметкой. \n",
    "Поэтому распространенным приемом является тренировка на похожем, но большом датасете и доучивание сети на целевом.\n",
    "\n",
    "Такой прием называют **Transfer Learning** или **Finetuning**.\n",
    "\n",
    "В сверточных сетях для классификации выделяют две части:\n",
    "- тело сети -- feature extractor, набор сверток и пулингов (convolutions and poolings)\n",
    "- голову -- это MLP (набор полносвязных слоев) после которых делается softmax и получаются вероятности разных классов.\n",
    "\n",
    "\n",
    "Вычислительно простым вариантом finetuning является обучение головы при замороженном feature extractor'е.\n",
    "\n",
    "Нам потребуется [предобученная модель](http://pytorch.org/docs/master/torchvision/datasets.html#torchvision-datasets) и датасет для нашей задачи.\n",
    "\n",
    "Предлагается воспользоваться моделью обученной на Imagenet, а в качестве целевого взять [Imagenette (это небольшое простое подмножество Imagenet)](https://github.com/fastai/imagenette)\n",
    "\n",
    "Архив с картинками доступен на\n",
    "https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz\n",
    "\n",
    "**Не запускайте на медленном канале! Весит ~95Mb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7356
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5368,
     "status": "ok",
     "timestamp": 1547408069394,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "k6YZmiwxY9yW",
    "outputId": "635c3449-a16e-4a57-9abf-df9a75bb6f59"
   },
   "outputs": [],
   "source": [
    "! wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz\n",
    "! tar xf imagenette2-160.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В файловой системе должны появиться папки:\n",
    "```bash\n",
    "$ tree --filelimit 10\n",
    "├── imagenette2-160\n",
    "│   ├── train\n",
    "│   │   ├── n01440764 [963 entries exceeds filelimit, not opening dir]\n",
    "│   │   ├── n02102040 [955 entries exceeds filelimit, not opening dir]\n",
    "│   │   ├── n02979186 [993 entries exceeds filelimit, not opening dir]\n",
    "│   │   ├── n03000684 [858 entries exceeds filelimit, not opening dir]\n",
    "│   │   ├── n03028079 [941 entries exceeds filelimit, not opening dir]\n",
    "│   │   ├── n03394916 [956 entries exceeds filelimit, not opening dir]\n",
    "│   │   ├── n03417042 [961 entries exceeds filelimit, not opening dir]\n",
    "│   │   ├── n03425413 [931 entries exceeds filelimit, not opening dir]\n",
    "│   │   ├── n03445777 [951 entries exceeds filelimit, not opening dir]\n",
    "│   │   └── n03888257 [960 entries exceeds filelimit, not opening dir]\n",
    "│   └── val\n",
    "│       ├── n01440764 [387 entries exceeds filelimit, not opening dir]\n",
    "│       ├── n02102040 [395 entries exceeds filelimit, not opening dir]\n",
    "│       ├── n02979186 [357 entries exceeds filelimit, not opening dir]\n",
    "│       ├── n03000684 [386 entries exceeds filelimit, not opening dir]\n",
    "│       ├── n03028079 [409 entries exceeds filelimit, not opening dir]\n",
    "│       ├── n03394916 [394 entries exceeds filelimit, not opening dir]\n",
    "│       ├── n03417042 [389 entries exceeds filelimit, not opening dir]\n",
    "│       ├── n03425413 [419 entries exceeds filelimit, not opening dir]\n",
    "│       ├── n03445777 [399 entries exceeds filelimit, not opening dir]\n",
    "│       └── n03888257 [390 entries exceeds filelimit, not opening dir]\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(160),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.CenterCrop(160),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(\"./imagenette2-160/train/\", transform=train_transform)\n",
    "val_dataset = ImageFolder(\"./imagenette2-160/val/\", transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выведите несколько примеров из train_dataset с метками.**\n",
    "\n",
    "**NB: Обратите внимание на преобразования, которые мы делаем над картинками и предупреждения, которые выдает `plt.imshow`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<your code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Модифицируйте модель так, чтобы она выдавала логиты на 10 классов, выберете для обучения только параметры измененного слоя.**\n",
    "\n",
    "Пояснение: все именнованные слои доступны как методы модели, если в `model_ft` есть слой `very_layer` его можно получить (и модифицировать) по имени:\n",
    "```\n",
    "print(model_ft.very_layer)\n",
    "model_ft.very_layer = nn.SomeLayer(...)\n",
    "```\n",
    "\n",
    "Все слои инициализируются в момент создания. Кроме того можно вызвать инициализацию руками, например так:\n",
    "```\n",
    "very_layer.weight.data.fill_(0.01)\n",
    "```\n",
    "\n",
    "Или воспользоваться уже написанными методами инициализации из модуля `torch.nn.init`\n",
    "```\n",
    "torch.nn.init.xavier_uniform(very_layer.weight)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-103a5810c899>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-103a5810c899>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    <your code>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "# hint: вы можете изучить устройство любого объекта в python пользуясь интерактивностью интерпретатора и методом dir()\n",
    "\n",
    "# Список слоев модели можно получить с помощью обхода\n",
    "# for x in model_ft.named_modules():\n",
    "#    print(x[0], x[1])\n",
    "\n",
    "# TODO: подмените в модели последний слой, чтобы она работала для 10 классов\n",
    "\n",
    "\n",
    "print('Before: ', list(model_ft.named_modules())[-1])\n",
    "<your code>\n",
    "\n",
    "print('After: ', list(model_ft.named_modules())[-1])\n",
    "\n",
    "# TODO: выберите, какие параметры дообучать.\n",
    "# для ускорения работы не забудьте выключить подсчёт градиента для всех необучаемых параметров \n",
    "# например, выключить обучение всех параметров можно при помощи этого кода:\n",
    "for params in model_ft.parameters():\n",
    "    params.requires_grad = False \n",
    "\n",
    "    \n",
    "params_to_train = []\n",
    "<your code>\n",
    "    \n",
    "# TODO: выберите, какие параметры дообучать.\n",
    "# для ускорения работы не забудьте выключить подсчёт градиента для всех необучаемых параметров \n",
    "# например, выключить обучение всех параметров можно при помощи этого кода:\n",
    "# for params in model_ft.parameters():\n",
    "#     params.requires_grad = False \n",
    "\n",
    "optimizer = torch.optim.SGD(params_to_train, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы воспользоваться GPU необходимо перенести модель и тензоры на устройство 'cuda'.\n",
    "Это делается с помощью операции `.to`:\n",
    "```\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "```\n",
    "\n",
    "Если что-то пойдет не так и тензоры окажутся на разных устройствах, просто вылетит исключение.\n",
    "Если у вас есть доступ к GPU, модифицируйте тренировочный цикл (функцию train_model) так, чтобы он мог работать и на GPU. Это существенно ускорит эксперименты.\n",
    "\n",
    "**Проведите несколько экспериментов:**\n",
    "- Случайная инициализация добавленного слоя + замороженный feature extractor\n",
    "- Случайная инициализация добавленного слоя + обучаемый feature extractor\n",
    "- Нулевая инициализация добавленного слоя + обучаемый feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: перепишите тренировочный цикл для работы на GPU\n",
    "def train_model(model, optimizer, trainloader, valloader, epochs=10, device='cpu'):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=512, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# random init + frozen FE\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "# Соберите модель правильно\n",
    "\n",
    "...\n",
    "optimizer = torch.optim.SGD(<...>, lr=0.001, momentum=0.9)\n",
    "train_model(model_ft, optimizer, train_loader, val_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random init + trainable FE\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "# Соберите модель правильно\n",
    "\n",
    "...\n",
    "optimizer = torch.optim.SGD(<...>, lr=0.001, momentum=0.9)\n",
    "train_model(model_ft, optimizer, train_loader, val_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero init + trainable FE\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "# Соберите модель правильно\n",
    "...\n",
    "optimizer = torch.optim.SGD(<...>, lr=0.001, momentum=0.9)\n",
    "train_model(model_ft, optimizer, train_loader, val_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какой вариант работает лучше?**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL18_seminar2_solved.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
